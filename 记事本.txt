奖励函数里增加了对姿态角的惩罚项，这奖励函数以后要大修。

11.27训练结果：能跑到3000步左右，现在姿态角越界不太多，多的是坠机越界。要把环境限制一下总时间，这样方便奖励函数设计

11.29 跳帧以后更不行了，甚至更差。周六把observation的维度区分开再训一训

DOING：
正在写动作归一化，即action space设为-1，1，然后用函数映射到实际范围。但是这样训出来的模型反而不如之前好。
尽管如此，应该还是进步了。因为以前的油门杆根本不动
目前的智能体仍然不会平飞，还是姿态角越界。我觉得是奖励函数的问题，而且还应该把之前几帧的状态观测量一起喂给算法，这样才能让他慢慢学会平飞。

TODO：
限制环境运行总时间，以规范奖励函数
把前几帧的数据都喂给算法
看一看gym的wrapper